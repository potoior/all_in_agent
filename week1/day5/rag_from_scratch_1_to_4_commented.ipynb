{
 "cells": [
  {
   "attachments": {
    "c566957c-a8ef-41a9-9b78-e089d35cf0b7.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABLMAAAN+CAYAAADuU0mGAAAMP2lDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnluSkEBCCSAgJfQmCEgJICWEFkB6EWyEJEAoMQaCiB1dVHDtYgEbuiqi2AGxI3YWwd4XRRSUdbFgV96kgK77yvfO9829//3nzH/OnDu3DADqp7hicQ6qAUCuKF8SGxLAGJucwiB1AwTggAYIgMDl5YlZ0dERANrg+e/27ib0hnbNQab1z/7/app8QR4PACQa4jR+Hi8X4kMA4JU8sSQfAKKMN5+aL5Zh2IC2BCYI8UIZzlDgShlOU+B9cp/4WDbEzQCoqHG5kgwAaG2QZxTwMqAGrQ9iJxFfKAJAnQGxb27uZD7EqRDbQB8xxDJ9ZtoPOhl/00wb0uRyM4awYi5yUwkU5olzuNP+z3L8b8vNkQ7GsIJNLVMSGiubM6zb7ezJ4TKsBnGvKC0yCmItiD8I+XJ/iFFKpjQ0QeGPGvLy2LBmQBdiJz43MBxiQ4iDRTmREUo+LV0YzIEYrhC0UJjPiYdYD+KFgrygOKXPZsnkWGUstC5dwmYp+QtciTyuLNZDaXYCS6n/OlPAUepjtKLM+CSIKRBbFAgTIyGmQeyYlx0XrvQZXZTJjhz0kUhjZflbQBwrEIUEKPSxgnRJcKzSvzQ3b3C+2OZMISdSiQ/kZ8aHKuqDNfO48vzhXLA2gYiVMKgjyBsbMTgXviAwSDF3rFsgSohT6nwQ5wfEKsbiFHFOtNIfNxPkhMh4M4hd8wrilGPxxHy4IBX6eLo4PzpekSdelMUNi1bkgy8DEYANAgEDSGFLA5NBFhC29tb3witFTzDgAgnIAALgoGQGRyTJe0TwGAeKwJ8QCUDe0LgAea8AFED+6xCrODqAdHlvgXxENngKcS4IBznwWiofJRqKlgieQEb4j+hc2Hgw3xzYZP3/nh9kvzMsyEQoGelgRIb6oCcxiBhIDCUGE21xA9wX98Yj4NEfNheciXsOzuO7P+EpoZ3wmHCD0EG4M0lYLPkpyzGgA+oHK2uR9mMtcCuo6YYH4D5QHSrjurgBcMBdYRwW7gcju0GWrcxbVhXGT9p/m8EPd0PpR3Yio+RhZH+yzc8jaXY0tyEVWa1/rI8i17SherOHen6Oz/6h+nx4Dv/ZE1uIHcTOY6exi9gxrB4wsJNYA9aCHZfhodX1RL66BqPFyvPJhjrCf8QbvLOySuY51Tj1OH1R9OULCmXvaMCeLJ4mEWZk5jNY8IsgYHBEPMcRDBcnF1cAZN8XxevrTYz8u4Hotnzn5v0BgM/JgYGBo9+5sJMA7PeAj/+R75wNE346VAG4cIQnlRQoOFx2IMC3hDp80vSBMTAHNnA+LsAdeAN/EATCQBSIB8lgIsw+E65zCZgKZoC5oASUgWVgNVgPNoGtYCfYAw6AenAMnAbnwGXQBm6Ae3D1dIEXoA+8A58RBCEhVISO6CMmiCVij7ggTMQXCUIikFgkGUlFMhARIkVmIPOQMmQFsh7ZglQj+5EjyGnkItKO3EEeIT3Ia+QTiqFqqDZqhFqhI1EmykLD0Xh0ApqBTkGL0PnoEnQtWoXuRuvQ0+hl9Abagb5A+zGAqWK6mCnmgDExNhaFpWDpmASbhZVi5VgVVos1wvt8DevAerGPOBGn4wzcAa7gUDwB5+FT8Fn4Ynw9vhOvw5vxa/gjvA//RqASDAn2BC8ChzCWkEGYSighlBO2Ew4TzsJnqYvwjkgk6hKtiR7wWUwmZhGnExcTNxD3Ek8R24mdxH4SiaRPsif5kKJIXFI+qYS0jrSbdJJ0ldRF+qCiqmKi4qISrJKiIlIpVilX2aVyQuWqyjOVz2QNsiXZixxF5pOnkZeSt5EbyVfIXeTPFE2KNcWHEk/JosylrKXUUs5S7lPeqKqqmql6qsaoClXnqK5V3ad6QfWR6kc1LTU7NbbaeDWp2hK1HWqn1O6ovaFSq[... 568888 chars omitted ...]"
    }
   },
   "cell_type": "markdown",
   "id": "41ce62a8-251f-4f9e-b375-e93a5861c3fe",
   "metadata": {},
   "source": [
    "# RAGä»é›¶å¼€å§‹æ•™ç¨‹ï¼šæ¦‚è¿°ä¸ç¯å¢ƒæ­å»º\n",
    "\n",
    "## æ•™ç¨‹ç›®æ ‡\n",
    "æœ¬æ•™ç¨‹å°†å¸¦ä½ ä»é›¶å¼€å§‹æ„å»ºRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰åº”ç”¨ç¨‹åºï¼Œé€æ­¥å»ºç«‹å¯¹RAGå…¨æ™¯çš„ç†è§£ã€‚\n",
    "\n",
    "## RAGæ¶æ„æ¦‚è§ˆ\n",
    "ä¸‹é¢çš„æ¶æ„å›¾å±•ç¤ºäº†RAGç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶å’Œå·¥ä½œæµç¨‹ï¼š\n",
    "\n",
    "![RAGæ¶æ„å›¾](attachment:c566957c-a8ef-41a9-9b78-e089d35cf0b7.png)\n",
    "\n",
    "## ç¯å¢ƒå‡†å¤‡\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…å’Œé…ç½®APIå¯†é’¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_packages",
   "metadata": {},
   "source": [
    "### æ­¥éª¤1ï¼šå®‰è£…æ ¸å¿ƒä¾èµ–åŒ…\n",
    "\n",
    "ä»¥ä¸‹åŒ…æ˜¯æ„å»ºRAGç³»ç»Ÿçš„åŸºç¡€ï¼š\n",
    "- **langchain_community**: LangChainç¤¾åŒºç‰ˆï¼Œæä¾›å„ç§æ–‡æ¡£åŠ è½½å™¨å’Œå·¥å…·\n",
    "- **tiktoken**: OpenAIçš„tokenè®¡æ•°å·¥å…·ï¼Œç”¨äºè®¡ç®—æ–‡æœ¬tokenæ•°é‡\n",
    "- **langchain-openai**: LangChainä¸OpenAIçš„é›†æˆåŒ…\n",
    "- **langchainhub**: LangChainçš„æç¤ºè¯ä»“åº“\n",
    "- **chromadb**: å¼€æºå‘é‡æ•°æ®åº“ï¼Œç”¨äºå­˜å‚¨æ–‡æ¡£åµŒå…¥å‘é‡\n",
    "- **langchain**: LangChainæ ¸å¿ƒæ¡†æ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…RAGç³»ç»Ÿæ‰€éœ€çš„æ ¸å¿ƒä¾èµ–åŒ…\n",
    "# è¿™äº›åŒ…å°†æ”¯æŒæ–‡æ¡£åŠ è½½ã€æ–‡æœ¬å¤„ç†ã€å‘é‡å­˜å‚¨å’ŒLLMé›†æˆç­‰åŠŸèƒ½\n",
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_langsmith",
   "metadata": {},
   "source": [
    "### æ­¥éª¤2ï¼šé…ç½®LangSmithï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "LangSmithæ˜¯LangChainçš„å¼€å‘å¹³å°ï¼Œç”¨äºè°ƒè¯•ã€æµ‹è¯•å’Œç›‘æ§LLMåº”ç”¨ã€‚\n",
    "å®ƒå¯ä»¥å¸®ä½ è¿½è¸ªé“¾çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œåˆ†ææ€§èƒ½ç“¶é¢ˆï¼Œä¼˜åŒ–æç¤ºè¯æ•ˆæœã€‚\n",
    "\n",
    "è®¿é—® https://docs.smith.langchain.com/ äº†è§£æ›´å¤šä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_langsmith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ“ä½œç³»ç»Ÿæ¨¡å—ï¼Œç”¨äºè®¾ç½®ç¯å¢ƒå˜é‡\n",
    "import os\n",
    "\n",
    "# é…ç½®LangSmithç¯å¢ƒå˜é‡ä»¥å¯ç”¨è°ƒè¯•å’Œç›‘æ§åŠŸèƒ½\n",
    "# LANGCHAIN_TRACING_V2: å¯ç”¨è¿½è¸ªåŠŸèƒ½ï¼Œè®°å½•è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "\n",
    "# LANGCHAIN_ENDPOINT: LangSmith APIçš„è®¿é—®ç«¯ç‚¹\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "\n",
    "# LANGCHAIN_API_KEY: ä½ çš„LangSmith APIå¯†é’¥\n",
    "# æ³¨æ„ï¼šè¯·æ›¿æ¢ <your-api-key> ä¸ºä½ çš„å®é™…APIå¯†é’¥\n",
    "os.environ['LANGCHAIN_API_KEY'] = <your-api-key>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_api_keys",
   "metadata": {},
   "source": [
    "### æ­¥éª¤3ï¼šé…ç½®OpenAI APIå¯†é’¥\n",
    "\n",
    "OpenAI APIå¯†é’¥æ˜¯è®¿é—®GPTæ¨¡å‹çš„å¿…éœ€å‡­è¯ã€‚\n",
    "ä½ å¯ä»¥ä» https://platform.openai.com/api-keys è·å–ä½ çš„APIå¯†é’¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_openai_api",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®OpenAI APIå¯†é’¥\n",
    "# è¿™æ˜¯è®¿é—®OpenAI GPTæ¨¡å‹çš„å¿…éœ€å‡­è¯\n",
    "# æ³¨æ„ï¼šè¯·æ›¿æ¢ <your-api-key> ä¸ºä½ çš„å®é™…OpenAI APIå¯†é’¥\n",
    "os.environ['OPENAI_API_KEY'] = <your-api-key>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_overview",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€éƒ¨åˆ†ï¼šRAGç³»ç»Ÿæ¦‚è§ˆ\n",
    "\n",
    "åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå®Œæ•´çš„RAGç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. **æ–‡æ¡£åŠ è½½**: ä»ç½‘é¡µè·å–å†…å®¹\n",
    "2. **æ–‡æ¡£åˆ†å‰²**: å°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆåˆé€‚å¤§å°çš„å—\n",
    "3. **å‘é‡åµŒå…¥**: å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º\n",
    "4. **å‘é‡å­˜å‚¨**: å°†åµŒå…¥å‘é‡å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“\n",
    "5. **æ£€ç´¢**: æ ¹æ®æŸ¥è¯¢æ‰¾åˆ°ç›¸å…³æ–‡æ¡£\n",
    "6. **ç”Ÿæˆ**: ä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n",
    "\n",
    "å‚è€ƒæ–‡æ¡£: [LangChain RAGå¿«é€Ÿå…¥é—¨](https://python.langchain.com/docs/use_cases/question_answering/quickstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indexing_section",
   "metadata": {},
   "source": [
    "### ğŸ” ç´¢å¼•é˜¶æ®µï¼ˆIndexingï¼‰\n",
    "\n",
    "ç´¢å¼•é˜¶æ®µæ˜¯RAGç³»ç»Ÿçš„åŸºç¡€ï¼Œè´Ÿè´£å°†æ–‡æ¡£è½¬æ¢ä¸ºå¯æ£€ç´¢çš„æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_rag_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—\n",
    "# ===========================\n",
    "\n",
    "# BeautifulSoup4: ç”¨äºè§£æHTMLç½‘é¡µå†…å®¹\n",
    "import bs4\n",
    "\n",
    "# LangChain Hub: ç¤¾åŒºå…±äº«çš„æç¤ºè¯ä»“åº“\n",
    "from langchain import hub\n",
    "\n",
    "# æ–‡æ¡£åˆ†å‰²å™¨ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆåˆé€‚å¤§å°çš„å—\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ç½‘é¡µåŠ è½½å™¨ï¼šä»æŒ‡å®šURLåŠ è½½ç½‘é¡µå†…å®¹\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Chromaå‘é‡æ•°æ®åº“ï¼šç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£åµŒå…¥å‘é‡\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# è¾“å‡ºè§£æå™¨ï¼šå°†LLMè¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# å¯è¿è¡Œç»„ä»¶ï¼šç”¨äºæ„å»ºå¤„ç†é“¾\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# OpenAIé›†æˆï¼šChatGPTæ¨¡å‹å’ŒåµŒå…¥æ¨¡å‹\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# ç´¢å¼•é˜¶æ®µï¼šæ–‡æ¡£å¤„ç†å’Œå­˜å‚¨\n",
    "# ===========================\n",
    "\n",
    "# æ­¥éª¤1: åŠ è½½æ–‡æ¡£\n",
    "# ä½¿ç”¨WebBaseLoaderä»æŒ‡å®šURLåŠ è½½åšå®¢æ–‡ç« \n",
    "# bs_kwargså‚æ•°ç”¨äºé…ç½®BeautifulSoupè§£æå™¨ï¼Œåªæå–ä¸»è¦å†…å®¹åŒºåŸŸ\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # ç›®æ ‡URL\n",
    "    bs_kwargs=dict(  # BeautifulSoupé…ç½®\n",
    "        parse_only=bs4.SoupStrainer(  # åªè§£æç‰¹å®šCSSç±»çš„å…ƒç´ \n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# æ‰§è¡ŒåŠ è½½æ“ä½œ\n",
    "docs = loader.load()\n",
    "print(f\"æˆåŠŸåŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "# æ­¥éª¤2: æ–‡æ¡£åˆ†å‰²\n",
    "# ä½¿ç”¨é€’å½’å­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨å°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆå°å—\n",
    "# chunk_size: æ¯ä¸ªæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°\n",
    "# chunk_overlap: ç›¸é‚»æ–‡æœ¬å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼Œä¿æŒè¯­ä¹‰è¿è´¯æ€§\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # æ¯ä¸ªchunkçº¦1000ä¸ªå­—ç¬¦\n",
    "    chunk_overlap=200  # é‡å 200ä¸ªå­—ç¬¦ä»¥ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œåˆ†å‰²æ“ä½œ\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"æ–‡æ¡£è¢«åˆ†å‰²æˆ {len(splits)} ä¸ªæ–‡æœ¬å—\")\n",
    "\n",
    "# æ­¥éª¤3: åˆ›å»ºå‘é‡å­˜å‚¨\n",
    "# ä½¿ç”¨Chromaå‘é‡æ•°æ®åº“å­˜å‚¨æ–‡æ¡£åµŒå…¥\n",
    "# OpenAIEmbeddingså°†æ–‡æœ¬è½¬æ¢ä¸º1536ç»´çš„å‘é‡è¡¨ç¤º\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,  # è¦å­˜å‚¨çš„æ–‡æ¡£å—\n",
    "    embedding=OpenAIEmbeddings()  # ä½¿ç”¨OpenAIçš„åµŒå…¥æ¨¡å‹\n",
    ")\n",
    "\n",
    "# ä»å‘é‡å­˜å‚¨åˆ›å»ºæ£€ç´¢å™¨\n",
    "# retrieverå°†ç”¨äºæ ¹æ®æŸ¥è¯¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£\n",
    "retriever = vectorstore.as_retriever()\n",
    "print(\"å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆï¼Œæ£€ç´¢å™¨å·²åˆå§‹åŒ–\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# æ£€ç´¢å’Œç”Ÿæˆé˜¶æ®µï¼šé—®ç­”ç³»ç»Ÿ\n",
    "# ===========================\n",
    "\n",
    "# æ­¥éª¤4: è·å–ä¼˜åŒ–çš„RAGæç¤ºè¯æ¨¡æ¿\n",
    "# ä»LangChain Hubè·å–ç»è¿‡ç¤¾åŒºéªŒè¯çš„RAGæç¤ºè¯\n",
    "# è¿™ä¸ªæç¤ºè¯æ¨¡æ¿ä¸“é—¨é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆä»»åŠ¡ä¼˜åŒ–\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(\"å·²è·å–RAGæç¤ºè¯æ¨¡æ¿\")\n",
    "\n",
    "# æ­¥éª¤5: åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹\n",
    "# ä½¿ç”¨GPT-3.5-turboæ¨¡å‹è¿›è¡Œç­”æ¡ˆç”Ÿæˆ\n",
    "# temperature=0: è®¾ç½®æ¸©åº¦ä¸º0ä»¥è·å¾—æœ€ç¡®å®šæ€§çš„å›ç­”\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",  # ä½¿ç”¨GPT-3.5-turboæ¨¡å‹\n",
    "    temperature=0  # æ¸©åº¦è®¾ä¸º0ï¼Œè·å¾—æœ€ç¨³å®šçš„å›ç­”\n",
    ")\n",
    "print(\"LLMæ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "# æ­¥éª¤6: å®šä¹‰æ–‡æ¡£æ ¼å¼åŒ–å‡½æ•°\n",
    "# è¿™ä¸ªå‡½æ•°å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå•ä¸ªå­—ç¬¦ä¸²\n",
    "# ç”¨äºå°†ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼ é€’ç»™LLM\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    å°†æ–‡æ¡£åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå•ä¸ªå­—ç¬¦ä¸²\n",
    "    \n",
    "    å‚æ•°:\n",
    "        docs: æ–‡æ¡£å¯¹è±¡åˆ—è¡¨\n",
    "    \n",
    "    è¿”å›:\n",
    "        str: æ‰€æœ‰æ–‡æ¡£å†…å®¹çš„è¿æ¥å­—ç¬¦ä¸²ï¼Œç”¨åŒæ¢è¡Œåˆ†éš”\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# æ­¥éª¤7: æ„å»ºRAGå¤„ç†é“¾\n",
    "# ä½¿ç”¨LangChainè¡¨è¾¾å¼è¯­è¨€(LCEL)æ„å»ºå¤„ç†æµæ°´çº¿\n",
    "# å¤„ç†æµç¨‹ï¼šæ£€ç´¢ â†’ æ ¼å¼åŒ– â†’ æç¤ºè¯å¡«å…… â†’ LLMç”Ÿæˆ â†’ è¾“å‡ºè§£æ\n",
    "rag_chain = (\n",
    "    # å¹¶è¡Œå¤„ç†ï¼šåŒæ—¶å‡†å¤‡ä¸Šä¸‹æ–‡å’Œæ¥æ”¶ç”¨æˆ·é—®é¢˜\n",
    "    {\n",
    "        \"context\": retriever | format_docs,  # æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶æ ¼å¼åŒ–\n",
    "        \"question\": RunnablePassthrough()  # ç›´æ¥ä¼ é€’ç”¨æˆ·é—®é¢˜\n",
    "    }\n",
    "    | prompt  # å°†ä¸Šä¸‹æ–‡å’Œé—®é¢˜å¡«å……åˆ°æç¤ºè¯æ¨¡æ¿\n",
    "    | llm  # ä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆ\n",
    "    | StrOutputParser()  # å°†LLMè¾“å‡ºè§£æä¸ºå­—ç¬¦ä¸²\n",
    ")\n",
    "print(\"RAGå¤„ç†é“¾æ„å»ºå®Œæˆ\")\n",
    "\n",
    "# æ­¥éª¤8: æ‰§è¡ŒRAGæŸ¥è¯¢\n",
    "# å‘ç³»ç»Ÿæé—®å¹¶è·å–åŸºäºæ£€ç´¢çŸ¥è¯†çš„å›ç­”\n",
    "question = \"What is Task Decomposition?\"\n",
    "print(f\"é—®é¢˜: {question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# è°ƒç”¨RAGé“¾è·å–ç­”æ¡ˆ\n",
    "answer = rag_chain.invoke(question)\n",
    "print(f\"ç­”æ¡ˆ: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_indexing_deep_dive",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒéƒ¨åˆ†ï¼šç´¢å¼•æ·±åº¦è§£æ\n",
    "\n",
    "åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ·±å…¥äº†è§£ç´¢å¼•è¿‡ç¨‹çš„æ¯ä¸ªç¯èŠ‚ï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. **Tokenè®¡æ•°**: ç†è§£æ–‡æœ¬çš„tokenæ¶ˆè€—\n",
    "2. **åµŒå…¥å‘é‡**: æ–‡æœ¬çš„æ•°å­¦è¡¨ç¤º\n",
    "3. **ç›¸ä¼¼åº¦è®¡ç®—**: å¦‚ä½•è¡¡é‡æ–‡æœ¬ç›¸ä¼¼æ€§\n",
    "4. **æ–‡æ¡£åŠ è½½**: ä»ä¸åŒæºè·å–æ–‡æ¡£\n",
    "5. **æ–‡æ¡£åˆ†å‰²**: ä¼˜åŒ–chunkå¤§å°å’Œé‡å åº¦\n",
    "6. **å‘é‡å­˜å‚¨**: é€‰æ‹©åˆé€‚çš„å‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "token_counting_section",
   "metadata": {},
   "source": [
    "### ğŸ”¢ Tokenè®¡æ•°åŸºç¡€\n",
    "\n",
    "Tokenæ˜¯LLMå¤„ç†æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚äº†è§£tokenè®¡æ•°æœ‰åŠ©äºï¼š\n",
    "- ä¼°ç®—APIè°ƒç”¨æˆæœ¬\n",
    "- é¿å…è¶…å‡ºæ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶\n",
    "- ä¼˜åŒ–æ–‡æœ¬å¤„ç†ç­–ç•¥\n",
    "\n",
    "**é‡è¦å‚è€ƒ**: [OpenAI Tokenè®¡æ•°æŒ‡å—](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
    "\n",
    "**ç»éªŒæ³•åˆ™**: çº¦4ä¸ªè‹±æ–‡å­—ç¬¦ â‰ˆ 1ä¸ªtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "token_counting_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹ï¼šç®€å•çš„é—®é¢˜å’Œç­”æ¡ˆ\n",
    "question = \"What kinds of pets do I like?\"  # é—®é¢˜ï¼šæˆ‘å–œæ¬¢ä»€ä¹ˆå® ç‰©ï¼Ÿ\n",
    "document = \"My favorite pet is a cat.\"  # æ–‡æ¡£ï¼šæˆ‘æœ€å–œæ¬¢çš„å® ç‰©æ˜¯çŒ«\n",
    "\n",
    "print(f\"é—®é¢˜: {question}\")\n",
    "print(f\"æ–‡æ¡£: {document}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tiktoken_usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥tiktokenåº“ï¼šOpenAIå®˜æ–¹çš„tokenè®¡æ•°å·¥å…·\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ–‡æœ¬å­—ç¬¦ä¸²ä¸­çš„tokenæ•°é‡\n",
    "    \n",
    "    å‚æ•°:\n",
    "        string: è¦è®¡æ•°çš„æ–‡æœ¬å­—ç¬¦ä¸²\n",
    "        encoding_name: ç¼–ç åç§°ï¼ˆå¦‚'cl100k_base'æ˜¯GPT-3.5/GPT-4ä½¿ç”¨çš„ç¼–ç ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "        int: æ–‡æœ¬ä¸­çš„tokenæ•°é‡\n",
    "    \"\"\"\n",
    "    # è·å–æŒ‡å®šçš„ç¼–ç å™¨\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    \n",
    "    # ç¼–ç æ–‡æœ¬å¹¶è®¡ç®—tokenæ•°é‡\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# è®¡ç®—é—®é¢˜çš„tokenæ•°é‡\n",
    "question_tokens = num_tokens_from_string(question, \"cl100k_base\")\n",
    "print(f\"é—®é¢˜ '{question}' åŒ…å« {question_tokens} ä¸ªtoken\")\n",
    "\n",
    "# è®¡ç®—æ–‡æ¡£çš„tokenæ•°é‡\n",
    "document_tokens = num_tokens_from_string(document, \"cl100k_base\")\n",
    "print(f\"æ–‡æ¡£ '{document}' åŒ…å« {document_tokens} ä¸ªtoken\")\n",
    "\n",
    "# è®¡ç®—æ€»tokenæ•°é‡\n",
    "total_tokens = question_tokens + document_tokens\n",
    "print(f\"æ€»tokenæ•°é‡: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embeddings_section",
   "metadata": {},
   "source": [
    "### ğŸ”® æ–‡æœ¬åµŒå…¥ï¼ˆEmbeddingsï¼‰\n",
    "\n",
    "æ–‡æœ¬åµŒå…¥æ˜¯å°†è‡ªç„¶è¯­è¨€æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡çš„è¿‡ç¨‹ã€‚è¿™äº›å‘é‡èƒ½å¤Ÿæ•æ‰æ–‡æœ¬çš„è¯­ä¹‰ä¿¡æ¯ã€‚\n",
    "\n",
    "**å…³é”®æ¦‚å¿µ**: \n",
    "- åµŒå…¥å‘é‡æ˜¯é«˜ç»´ç©ºé—´ä¸­çš„ç‚¹ï¼ˆé€šå¸¸æ˜¯1536ç»´ï¼‰\n",
    "- è¯­ä¹‰ç›¸ä¼¼çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘\n",
    "- åµŒå…¥æ˜¯RAGç³»ç»Ÿæ£€ç´¢çš„åŸºç¡€\n",
    "\n",
    "**å‚è€ƒæ–‡æ¡£**: [OpenAIæ–‡æœ¬åµŒå…¥æ¨¡å‹](https://python.langchain.com/docs/integrations/text_embedding/openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embeddings_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥OpenAIåµŒå…¥æ¨¡å‹\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹\n",
    "# é»˜è®¤ä½¿ç”¨text-embedding-ada-002æ¨¡å‹\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "# ä¸ºé—®é¢˜å’Œæ–‡æ¡£ç”ŸæˆåµŒå…¥å‘é‡\n",
    "print(\"æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...\")\n",
    "query_result = embd.embed_query(question)  # é—®é¢˜çš„åµŒå…¥å‘é‡\n",
    "document_result = embd.embed_query(document)  # æ–‡æ¡£çš„åµŒå…¥å‘é‡\n",
    "\n",
    "# æ˜¾ç¤ºåµŒå…¥å‘é‡çš„ç»´åº¦\n",
    "print(f\"åµŒå…¥å‘é‡ç»´åº¦: {len(query_result)}\")\n",
    "print(f\"é—®é¢˜åµŒå…¥å‘é‡çš„å‰10ä¸ªå€¼: {query_result[:10]}\")\n",
    "print(f\"æ–‡æ¡£åµŒå…¥å‘é‡çš„å‰10ä¸ªå€¼: {document_result[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similarity_section",
   "metadata": {},
   "source": [
    "### ğŸ“ ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—\n",
    "\n",
    "ä½™å¼¦ç›¸ä¼¼åº¦æ˜¯è¡¡é‡ä¸¤ä¸ªå‘é‡ç›¸ä¼¼ç¨‹åº¦çš„æŒ‡æ ‡ï¼Œåœ¨RAGç³»ç»Ÿä¸­ç”¨äºï¼š\n",
    "- æ‰¾åˆ°ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£\n",
    "- è¡¡é‡æ–‡æœ¬è¯­ä¹‰ç›¸ä¼¼æ€§\n",
    "- æ’åºæ£€ç´¢ç»“æœ\n",
    "\n",
    "**æ•°å€¼èŒƒå›´**: -1ï¼ˆå®Œå…¨ä¸ç›¸ä¼¼ï¼‰åˆ° 1ï¼ˆå®Œå…¨ç›¸åŒï¼‰\n",
    "\n",
    "**å‚è€ƒæ–‡æ¡£**: [OpenAIåµŒå…¥ç›¸ä¼¼åº¦æŒ‡å—](https://platform.openai.com/docs/guides/embeddings/frequently-asked-questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosine_similarity_calc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥NumPyåº“è¿›è¡Œæ•°å€¼è®¡ç®—\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    \n",
    "    å‚æ•°:\n",
    "        vec1: ç¬¬ä¸€ä¸ªå‘é‡\n",
    "        vec2: ç¬¬äºŒä¸ªå‘é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "        float: ä½™å¼¦ç›¸ä¼¼åº¦ (-1åˆ°1ä¹‹é—´)\n",
    "    \"\"\"\n",
    "    # è®¡ç®—ç‚¹ç§¯\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    \n",
    "    # è®¡ç®—å‘é‡çš„L2èŒƒæ•°ï¼ˆé•¿åº¦ï¼‰\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    # å…¬å¼: cos(Î¸) = (AÂ·B) / (||A|| Ã— ||B||)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity\n",
    "\n",
    "# è®¡ç®—é—®é¢˜å’Œæ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼åº¦\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(f\"é—®é¢˜ä¸æ–‡æ¡£çš„ä½™å¼¦ç›¸ä¼¼åº¦: {similarity:.4f}\")\n",
    "\n",
    "# è§£é‡Šç›¸ä¼¼åº¦ç»“æœ\n",
    "if similarity > 0.8:\n",
    "    print(\"âœ… é«˜åº¦ç›¸ä¼¼ - æ–‡æ¡£å¾ˆå¯èƒ½åŒ…å«é—®é¢˜çš„ç­”æ¡ˆ\")\n",
    "elif similarity > 0.5:\n",
    "    print(\"ğŸŸ¡ ä¸­ç­‰ç›¸ä¼¼ - æ–‡æ¡£å¯èƒ½éƒ¨åˆ†ç›¸å…³\")\n",
    "elif similarity > 0:\n",
    "    print(\"ğŸ” ä½ç›¸ä¼¼åº¦ - æ–‡æ¡£ç•¥æœ‰ç›¸å…³æ€§\")\n",
    "else:\n",
    "    print(\"âŒ è´Ÿç›¸ä¼¼åº¦ - æ–‡æ¡£å¯èƒ½ä¸ç›¸å…³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "document_loaders_section",
   "metadata": {},
   "source": [
    "### ğŸ“– æ–‡æ¡£åŠ è½½å™¨è¯¦è§£\n",
    "\n",
    "æ–‡æ¡£åŠ è½½å™¨æ˜¯RAGç³»ç»Ÿçš„å…¥å£ï¼Œè´Ÿè´£ä»å„ç§æ•°æ®æºè·å–å†…å®¹ã€‚\n",
    "\n",
    "**æ”¯æŒçš„æ–‡æ¡£æº**: \n",
    "- ç½‘é¡µ (HTML)\n",
    "- PDFæ–‡ä»¶\n",
    "- Wordæ–‡æ¡£\n",
    "- æ–‡æœ¬æ–‡ä»¶\n",
    "- æ•°æ®åº“\n",
    "- äº‘å­˜å‚¨æœåŠ¡\n",
    "\n",
    "**å‚è€ƒæ–‡æ¡£**: [LangChainæ–‡æ¡£åŠ è½½å™¨](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "web_loader_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# ä»ç½‘é¡µåŠ è½½æ–‡æ¡£ç¤ºä¾‹\n",
    "# ===========================\n",
    "\n",
    "# é‡æ–°å¯¼å…¥å¿…è¦çš„åº“ï¼ˆæ¼”ç¤ºå®Œæ•´æµç¨‹ï¼‰\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# åˆ›å»ºç½‘é¡µåŠ è½½å™¨å®ä¾‹\n",
    "# è¿™æ¬¡æˆ‘ä»¬å°†åŠ è½½ä¸€ç¯‡å…³äºAI Agentçš„åšå®¢æ–‡ç« \n",
    "loader = WebBaseLoader(\n",
    "    # è¦åŠ è½½çš„ç½‘é¡µURLåˆ—è¡¨\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    \n",
    "    # BeautifulSoupè§£æå™¨é…ç½®\n",
    "    bs_kwargs=dict(\n",
    "        # ä½¿ç”¨SoupStraineråªè§£æç‰¹å®šçš„HTMLå…ƒç´ \n",
    "        # è¿™æ ·å¯ä»¥è¿‡æ»¤æ‰å¯¼èˆªæ ã€å¹¿å‘Šç­‰æ— å…³å†…å®¹\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            # åªæå–å…·æœ‰è¿™äº›CSSç±»çš„HTMLå…ƒç´ \n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# æ‰§è¡ŒåŠ è½½æ“ä½œ\n",
    "print(\"æ­£åœ¨åŠ è½½ç½‘é¡µå†…å®¹...\")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# æ˜¾ç¤ºåŠ è½½ç»“æœ\n",
    "print(f\"âœ… æˆåŠŸåŠ è½½ {len(blog_docs)} ä¸ªæ–‡æ¡£å¯¹è±¡\")\n",
    "\n",
    "# æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å†…å®¹\n",
    "if blog_docs:\n",
    "    first_doc = blog_docs[0]\n",
    "    print(f\"\\nç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®:\")\n",
    "    print(f\"  - æ¥æº: {first_doc.metadata.get('source', 'æœªçŸ¥')}\")\n",
    "    print(f\"  - æ ‡é¢˜: {first_doc.metadata.get('title', 'æœªçŸ¥')}\")\n",
    "    print(f\"  - å†…å®¹é•¿åº¦: {len(first_doc.page_content)} å­—ç¬¦\")\n",
    "    print(f\"  - å†…å®¹é¢„è§ˆ: {first_doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "text_splitting_section",
   "metadata": {},
   "source": [
    "### âœ‚ï¸ æ–‡æœ¬åˆ†å‰²ç­–ç•¥\n",
    "\n",
    "æ–‡æœ¬åˆ†å‰²æ˜¯RAGç³»ç»Ÿçš„å…³é”®æ­¥éª¤ï¼Œå½±å“æ£€ç´¢è´¨é‡å’Œæ•ˆç‡ã€‚\n",
    "\n",
    "**åˆ†å‰²ç­–ç•¥**: \n",
    "- **é€’å½’å­—ç¬¦åˆ†å‰²**: æŒ‰å­—ç¬¦é¡ºåºå°è¯•åˆ†å‰²ï¼ˆæ¨èé€šç”¨æ–‡æœ¬ï¼‰\n",
    "- **Tokençº§åˆ†å‰²**: åŸºäºtokenæ•°é‡åˆ†å‰²\n",
    "- **è¯­ä¹‰åˆ†å‰²**: åŸºäºå†…å®¹è¯­ä¹‰è¿›è¡Œåˆ†å‰²\n",
    "\n",
    "**å…³é”®å‚æ•°**: \n",
    "- **chunk_size**: æ¯ä¸ªæ–‡æœ¬å—çš„å¤§å°\n",
    "- **chunk_overlap**: ç›¸é‚»å—çš„é‡å åº¦\n",
    "\n",
    "**å‚è€ƒæ–‡æ¡£**: [é€’å½’å­—ç¬¦åˆ†å‰²å™¨](https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text_splitting_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥é€’å½’å­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨å®ä¾‹\n",
    "# from_tiktoken_encoder: ä½¿ç”¨ä¸OpenAIç›¸åŒçš„tokenè®¡æ•°æ–¹å¼\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,  # æ¯ä¸ªæ–‡æœ¬å—çº¦300ä¸ªtoken\n",
    "    chunk_overlap=50  # ç›¸é‚»å—é‡å 50ä¸ªtokenä»¥ä¿æŒè¿è´¯æ€§\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œåˆ†å‰²æ“ä½œ\n",
    "print(\"æ­£åœ¨åˆ†å‰²æ–‡æ¡£...\")\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# æ˜¾ç¤ºåˆ†å‰²ç»“æœ\n",
    "print(f\"âœ… æ–‡æ¡£è¢«åˆ†å‰²æˆ {len(splits)} ä¸ªæ–‡æœ¬å—\")\n",
    "\n",
    "# åˆ†æåˆ†å‰²ç»“æœ\n",
    "if splits:\n",
    "    print(f\"\\nåˆ†å‰²ç»Ÿè®¡:\")\n",
    "    chunk_lengths = [len(chunk.page_content) for chunk in splits]\n",
    "    print(f\"  - å¹³å‡å—é•¿åº¦: {sum(chunk_lengths) / len(chunk_lengths):.0f} å­—ç¬¦\")\n",
    "    print(f\"  - æœ€å°å—é•¿åº¦: {min(chunk_lengths)} å­—ç¬¦\")\n",
    "    print(f\"  - æœ€å¤§å—é•¿åº¦: {max(chunk_lengths)} å­—ç¬¦\")\n",
    "    \n",
    "    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ–‡æœ¬å—\n",
    "    print(f\"\\nç¬¬ä¸€ä¸ªæ–‡æœ¬å— (é•¿åº¦: {len(splits[0].page_content)}):\")\n",
    "    print(f\"{splits[0].page_content[:200]}...\")\n",
    "    \n",
    "    print(f\"\\næœ€åä¸€ä¸ªæ–‡æœ¬å— (é•¿åº¦: {len(splits[-1].page_content)}):\")\n",
    "    print(f\"{splits[-1].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vectorstore_section",
   "metadata": {},
   "source": [
    "### ğŸ—„ï¸ å‘é‡å­˜å‚¨é€‰æ‹©\n",
    "\n",
    "å‘é‡å­˜å‚¨æ˜¯RAGç³»ç»Ÿçš„è®°å¿†ä¸­æ¢ï¼Œè´Ÿè´£é«˜æ•ˆå­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡ã€‚\n",
    "\n",
    "**æµè¡Œçš„å‘é‡æ•°æ®åº“**: \n",
    "- **Chroma**: å¼€æºï¼Œè½»é‡çº§ï¼Œé€‚åˆåŸå‹å¼€å‘\n",
    "- **Pinecone**: æ‰˜ç®¡æœåŠ¡ï¼Œé«˜æ€§èƒ½ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ\n",
    "- **Weaviate**: å¼€æºï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œæ”¯æŒæ··åˆæœç´¢\n",
    "- **Qdrant**: å¼€æºï¼Œé«˜æ€§èƒ½ï¼Œæ”¯æŒè¿‡æ»¤\n",
    "\n",
    "**å‚è€ƒæ–‡æ¡£**: [LangChainå‘é‡å­˜å‚¨é›†æˆ](https://python.langchain.com/docs/integrations/vectorstores/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vectorstore_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å‘é‡å­˜å‚¨ç›¸å…³åº“\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# åˆ›å»ºå‘é‡å­˜å‚¨\n",
    "# è¿™å°†ï¼š\n",
    "# 1. ä¸ºæ¯ä¸ªæ–‡æœ¬å—ç”ŸæˆåµŒå…¥å‘é‡\n",
    "# 2. å°†å‘é‡å’ŒåŸå§‹æ–‡æœ¬å­˜å‚¨åˆ°Chromaæ•°æ®åº“\n",
    "# 3. åˆ›å»ºç´¢å¼•ä»¥æ”¯æŒå¿«é€Ÿç›¸ä¼¼åº¦æœç´¢\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,  # è¦å­˜å‚¨çš„æ–‡æ¡£å—\n",
    "    embedding=OpenAIEmbeddings(),  # ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹\n",
    "    # collection_name: å¯ä»¥æŒ‡å®šé›†åˆåç§°ï¼Œé»˜è®¤ä¸ºéšæœºUUID\n",
    "    # persist_directory: å¯ä»¥æŒ‡å®šæŒä¹…åŒ–ç›®å½•ï¼Œé»˜è®¤åœ¨å†…å­˜ä¸­\n",
    ")\n",
    "\n",
    "# ä»å‘é‡å­˜å‚¨åˆ›å»ºæ£€ç´¢å™¨\n",
    "# æ£€ç´¢å™¨æä¾›äº†æ›´ç®€å•çš„æ¥å£æ¥æœç´¢ç›¸å…³æ–‡æ¡£\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"âœ… å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"å­˜å‚¨çš„æ–‡æ¡£æ•°é‡: {vectorstore._collection.count()}\")\n",
    "\n",
    "# æµ‹è¯•å‘é‡å­˜å‚¨çš„åŸºæœ¬åŠŸèƒ½\n",
    "test_query = \"What is an AI agent?\"\n",
    "print(f\"\\næµ‹è¯•æŸ¥è¯¢: '{test_query}'\")\n",
    "\n",
    "# æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢\n",
    "similar_docs = vectorstore.similarity_search(test_query, k=3)\n",
    "print(f\"\\næ‰¾åˆ° {len(similar_docs)} ä¸ªç›¸å…³æ–‡æ¡£:\")\n",
    "\n",
    "for i, doc in enumerate(similar_docs, 1):\n",
    "    print(f\"\\næ–‡æ¡£ {i}:\")\n",
    "    print(f\"  å†…å®¹: {doc.page_content[:150]}...\")\n",
    "    print(f\"  é•¿åº¦: {len(doc.page_content)} å­—ç¬¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieval_section",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ£€ç´¢æœºåˆ¶è¯¦è§£\n",
    "\n",
    "æ£€ç´¢æ˜¯RAGç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œè´Ÿè´£æ‰¾åˆ°ä¸ç”¨æˆ·æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚\n",
    "\n",
    "**æ£€ç´¢ç­–ç•¥**: \n",
    "- **ç›¸ä¼¼åº¦æ£€ç´¢**: åŸºäºå‘é‡ç›¸ä¼¼åº¦\n",
    "- **MMRæ£€ç´¢**: æœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼Œå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§\n",
    "- **è¿‡æ»¤æ£€ç´¢**: åŸºäºå…ƒæ•°æ®è¿‡æ»¤ç»“æœ\n",
    "\n",
    "**å…³é”®å‚æ•°**: \n",
    "- **k**: è¿”å›çš„æ–‡æ¡£æ•°é‡\n",
    "- **score_threshold**: ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "- **fetch_k**: åˆå§‹è·å–çš„æ–‡æ¡£æ•°é‡ï¼ˆç”¨äºMMRï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retrieval_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºé…ç½®äº†ç‰¹å®šå‚æ•°çš„æ£€ç´¢å™¨\n",
    "# search_kwargså…è®¸æˆ‘ä»¬è‡ªå®šä¹‰æœç´¢è¡Œä¸º\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 1  # åªè¿”å›æœ€ç›¸å…³çš„1ä¸ªæ–‡æ¡£\n",
    "    }\n",
    ")\n",
    "\n",
    "# æµ‹è¯•æ£€ç´¢åŠŸèƒ½\n",
    "query = \"What is Task Decomposition?\"\n",
    "print(f\"æŸ¥è¯¢: '{query}'\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# è·å–ç›¸å…³æ–‡æ¡£\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# æ˜¾ç¤ºæ£€ç´¢ç»“æœ\n",
    "print(f\"æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "if docs:\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"\\næ–‡æ¡£ {i}:\")\n",
    "        print(f\"  å†…å®¹: {doc.page_content}\")\n",
    "        print(f\"  é•¿åº¦: {len(doc.page_content)} å­—ç¬¦\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæ–‡æ¡£çš„å…ƒæ•°æ®\n",
    "        if hasattr(doc, 'metadata') and doc.metadata:\n",
    "            print(f\"  å…ƒæ•°æ®: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generation_section",
   "metadata": {},
   "source": [
    "## ç¬¬å››éƒ¨åˆ†ï¼šç”Ÿæˆç­–ç•¥ä¼˜åŒ–\n",
    "\n",
    "ç”Ÿæˆé˜¶æ®µå°†æ£€ç´¢åˆ°çš„ä¿¡æ¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ç­”æ¡ˆã€‚\n",
    "\n",
    "**ç”Ÿæˆä¼˜åŒ–æŠ€å·§**: \n",
    "- **æç¤ºè¯å·¥ç¨‹**: è®¾è®¡æ›´å¥½çš„æç¤ºè¯æ¨¡æ¿\n",
    "- **ä¸Šä¸‹æ–‡ç®¡ç†**: ä¼˜åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç»„ç»‡æ–¹å¼\n",
    "- **å‚æ•°è°ƒä¼˜**: è°ƒæ•´temperatureã€top_pç­‰å‚æ•°\n",
    "- **åå¤„ç†**: å¯¹ç”Ÿæˆç»“æœè¿›è¡Œæ¸…æ´—å’Œæ ¼å¼åŒ–\n",
    "\n",
    "**å‚è€ƒèµ„æº**: [LangChain Hubæç¤ºè¯](https://smith.langchain.com/hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt_template_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥OpenAIèŠå¤©æ¨¡å‹\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# å¯¼å…¥æç¤ºè¯æ¨¡æ¿åŠŸèƒ½\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆ›å»ºè‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿\n",
    "# è¿™ä¸ªæ¨¡æ¿æ˜ç¡®æŒ‡ç¤ºæ¨¡å‹ä»…åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜\n",
    "template = \"\"\"Answer the question based only on the following context:
",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# ä»æ¨¡æ¿åˆ›å»ºæç¤ºè¯å¯¹è±¡\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# æ˜¾ç¤ºæç¤ºè¯æ¨¡æ¿ç»“æ„\n",
    "print(\"è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿:\")\n",
    "print(prompt)\n",
    "print()\n",
    "\n",
    "# æ˜¾ç¤ºæ¨¡æ¿çš„æ¶ˆæ¯æ ¼å¼\n",
    "print(\"æ¨¡æ¿æ ¼å¼åŒ–ä¸ºæ¶ˆæ¯:\")\n",
    "messages = prompt.format_messages(\n",
    "    context=\"AI agents are autonomous programs that can perform tasks.\",\n",
    "    question=\"What is an AI agent?\"\n",
    ")\n",
    "for msg in messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm_initialization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–èŠå¤©æ¨¡å‹\n",
    "# ä½¿ç”¨GPT-3.5-turboæ¨¡å‹ï¼Œè®¾ç½®temperature=0è·å¾—æœ€ç¡®å®šçš„å›ç­”\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",  # ä½¿ç”¨GPT-3.5-turboæ¨¡å‹\n",
    "    temperature=0  # æ¸©åº¦è®¾ä¸º0ï¼Œè·å¾—æœ€ç¨³å®šã€ç¡®å®šçš„å›ç­”\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLMæ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")\n",
    "print(f\"  - æ¨¡å‹: {llm.model_name}\")\n",
    "print(f\"  - æ¸©åº¦: {llm.temperature}\")\n",
    "print(f\"  - æœ€å¤§token: {llm.max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple_chain_creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç®€å•çš„å¤„ç†é“¾\n",
    "# ä½¿ç”¨ç®¡é“æ“ä½œç¬¦(|)è¿æ¥æç¤ºè¯å’ŒLLM\n",
    "chain = prompt | llm\n",
    "\n",
    "print(\"âœ… å¤„ç†é“¾åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"é“¾ç»“æ„: {chain}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple_chain_execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œç®€å•çš„é—®ç­”\n",
    "# ä½¿ç”¨ä¹‹å‰æ£€ç´¢åˆ°çš„æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡\n",
    "print(\"æ‰§è¡Œé—®ç­”...\")\n",
    "print(f\"é—®é¢˜: What is Task Decomposition?\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# è°ƒç”¨é“¾è·å–ç­”æ¡ˆ\n",
    "# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ä¹‹å‰æ£€ç´¢åˆ°çš„docsä½œä¸ºä¸Šä¸‹æ–‡\n",
    "response = chain.invoke({\n",
    "    \"context\": docs,  # æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£\n",
    "    \"question\": \"What is Task Decomposition?\"  # ç”¨æˆ·é—®é¢˜\n",
    "})\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ\n",
    "print(f\"ç­”æ¡ˆ: {response.content}\")\n",
    "print(f\"ä½¿ç”¨çš„token: {response.response_metadata['token_usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langchain_hub_section",
   "metadata": {},
   "source": [
    "### ğŸ¯ ä½¿ç”¨LangChain Hubä¼˜åŒ–æç¤ºè¯\n",
    "\n",
    "LangChain Hubæ˜¯ç¤¾åŒºå…±äº«çš„æç¤ºè¯æ¨¡æ¿åº“ï¼ŒåŒ…å«ç»è¿‡éªŒè¯çš„ä¼˜è´¨æç¤ºè¯ã€‚\n",
    "\n",
    "**ä¼˜åŠ¿**: \n",
    "- âœ… ç»è¿‡ç¤¾åŒºéªŒè¯å’Œä¼˜åŒ–\n",
    "- âœ… éµå¾ªæœ€ä½³å®è·µ\n",
    "- âœ… æŒç»­æ›´æ–°å’Œæ”¹è¿›\n",
    "- âœ… èŠ‚çœæç¤ºè¯è®¾è®¡æ—¶é—´\n",
    "\n",
    "**å¸¸ç”¨RAGæç¤ºè¯**: \n",
    "- `rlm/rag-prompt`: æ ‡å‡†RAGæç¤ºè¯\n",
    "- `rlm/rag-prompt-multi-query`: å¤šæŸ¥è¯¢RAG\n",
    "- `rlm/rag-prompt-contextual`: ä¸Šä¸‹æ–‡æ„ŸçŸ¥RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hub_prompt_usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»LangChain Hubè·å–ä¼˜åŒ–çš„RAGæç¤ºè¯\n",
    "# rlm/rag-promptæ˜¯ç¤¾åŒºå¹¿æ³›ä½¿ç”¨çš„RAGæç¤ºè¯æ¨¡æ¿\n",
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(\"âœ… ä»Hubè·å–RAGæç¤ºè¯æ¨¡æ¿\")\n",
    "print(f\"æç¤ºè¯åç§°: rlm/rag-prompt\")\n",
    "print(f\"æç¤ºè¯ç±»å‹: {type(prompt_hub_rag)}\")\n",
    "\n",
    "# æ˜¾ç¤ºæç¤ºè¯æ¨¡æ¿çš„ç»“æ„\n",
    "print(f\"\\næç¤ºè¯æ¨¡æ¿è¯¦æƒ…:\")\n",
    "print(prompt_hub_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hub_prompt_details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹æç¤ºè¯æ¨¡æ¿çš„å…·ä½“å†…å®¹\n",
    "# è¿™æ˜¾ç¤ºäº†æ¨¡æ¿ä½¿ç”¨çš„å…·ä½“æŒ‡ä»¤å’Œæ ¼å¼\n",
    "print(\"æç¤ºè¯æ¨¡æ¿å†…å®¹:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# è·å–æ¨¡æ¿çš„å­—ç¬¦ä¸²è¡¨ç¤º\n",
    "template_string = str(prompt_hub_rag)\n",
    "print(template_string)\n",
    "\n",
    "# åˆ†ææ¨¡æ¿çš„è¾“å…¥å˜é‡\n",
    "print(f\"\\næ¨¡æ¿è¾“å…¥å˜é‡: {prompt_hub_rag.input_variables}\")\n",
    "print(f\"æ¨¡æ¿ç±»å‹: {prompt_hub_rag.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag_chain_final_section",
   "metadata": {},
   "source": [
    "### ğŸ”— æ„å»ºå®Œæ•´çš„RAGé“¾\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†æ‰€æœ‰ç»„ä»¶ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„RAGå¤„ç†é“¾ã€‚\n",
    "\n",
    "**é“¾å¼å¤„ç†æµç¨‹**: \n",
    "1. **è¾“å…¥å¤„ç†**: æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢\n",
    "2. **æ–‡æ¡£æ£€ç´¢**: æ‰¾åˆ°ç›¸å…³æ–‡æ¡£\n",
    "3. **ä¸Šä¸‹æ–‡æ ¼å¼åŒ–**: å°†æ–‡æ¡£æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²\n",
    "4. **æç¤ºè¯å¡«å……**: æ„å»ºå®Œæ•´çš„æç¤ºè¯\n",
    "5. **LLMç”Ÿæˆ**: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n",
    "6. **è¾“å‡ºè§£æ**: æå–çº¯æ–‡æœ¬ç­”æ¡ˆ\n",
    "\n",
    "**å‚è€ƒæ–‡æ¡£**: [RAGé“¾ç¤ºä¾‹](https://python.langchain.com/docs/expression_language/get_started#rag-search-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_rag_chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥é“¾å¼å¤„ç†æ‰€éœ€çš„ç»„ä»¶\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# ä½¿ç”¨LangChainè¡¨è¾¾å¼è¯­è¨€(LCEL)æ„å»ºå®Œæ•´çš„RAGé“¾\n",
    "# è¿™ç§å£°æ˜å¼çš„æ–¹å¼ä½¿é“¾çš„ç»“æ„æ¸…æ™°ä¸”æ˜“äºç»´æŠ¤\n",
    "rag_chain = (\n",
    "    # æ­¥éª¤1: å¹¶è¡Œå‡†å¤‡è¾“å…¥æ•°æ®\n",
    "    {\n",
    "        # æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²\n",
    "        \"context\": retriever | format_docs,\n",
    "        \n",
    "        # ç›´æ¥ä¼ é€’ç”¨æˆ·é—®é¢˜ï¼ˆä¸ç»è¿‡å¤„ç†ï¼‰\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    \n",
    "    # æ­¥éª¤2: ä½¿ç”¨Hubçš„ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿\n",
    "    | prompt_hub_rag\n",
    "    \n",
    "    # æ­¥éª¤3: ä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆ\n",
    "    | llm\n",
    "    \n",
    "    # æ­¥éª¤4: è§£æè¾“å‡ºä¸ºçº¯å­—ç¬¦ä¸²\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… å®Œæ•´çš„RAGé“¾æ„å»ºå®Œæˆ\")\n",
    "print(f\"é“¾ç»“æ„: {type(rag_chain)}\")\n",
    "print(\"å¤„ç†æµç¨‹: è¾“å…¥ â†’ æ£€ç´¢ â†’ æ ¼å¼åŒ– â†’ æç¤ºè¯ â†’ LLM â†’ è§£æ â†’ è¾“å‡º\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_rag_execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œå®Œæ•´çš„RAGæŸ¥è¯¢\n",
    "# è¿™æ¬¡ä½¿ç”¨Hubçš„ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿\n",
    "question = \"What is Task Decomposition?\"\n",
    "print(f\"ğŸ¤” é—®é¢˜: {question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# è®°å½•å¼€å§‹æ—¶é—´\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# æ‰§è¡ŒRAGé“¾\n",
    "print(\"ğŸ”„ æ­£åœ¨æ‰§è¡ŒRAGå¤„ç†...\")\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "# è®¡ç®—æ‰§è¡Œæ—¶é—´\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ\n",
    "print(f\"âœ… å¤„ç†å®Œæˆ (è€—æ—¶: {execution_time:.2f}ç§’)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“ ç­”æ¡ˆ:\")\n",
    "print(answer)\n",
    "\n",
    "# éªŒè¯ç­”æ¡ˆè´¨é‡\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š ç­”æ¡ˆè´¨é‡æ£€æŸ¥:\")\n",
    "print(f\"  - ç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦\")\n",
    "print(f\"  - åŒ…å«å…³é”®è¯ 'Task Decomposition': {'Task Decomposition' in answer}\")\n",
    "print(f\"  - ç­”æ¡ˆå®Œæ•´æ€§: {'...' not in answer[-10:]}\")  # æ£€æŸ¥æ˜¯å¦å®Œæ•´ç»“æŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## ğŸ‰ ç¬¬ä¸€éƒ¨åˆ†æ€»ç»“\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†RAGç³»ç»Ÿçš„ç¬¬ä¸€éƒ¨åˆ†å­¦ä¹ ï¼åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ï¼š\n",
    "\n",
    "### âœ… å®Œæˆçš„æ ¸å¿ƒä»»åŠ¡\n",
    "1. **ç¯å¢ƒæ­å»º**: å®‰è£…äº†æ‰€æœ‰å¿…éœ€çš„ä¾èµ–åŒ…\n",
    "2. **APIé…ç½®**: è®¾ç½®äº†OpenAIå’ŒLangSmith\n",
    "3. **æ–‡æ¡£å¤„ç†**: å­¦ä¼šäº†åŠ è½½ã€åˆ†å‰²å’Œå­˜å‚¨æ–‡æ¡£\n",
    "4. **å‘é‡åµŒå…¥**: ç†è§£äº†æ–‡æœ¬å¦‚ä½•è½¬æ¢ä¸ºå‘é‡\n",
    "5. **ç›¸ä¼¼åº¦è®¡ç®—**: æŒæ¡äº†ä½™å¼¦ç›¸ä¼¼åº¦çš„è®¡ç®—å’Œåº”ç”¨\n",
    "6. **æ£€ç´¢æœºåˆ¶**: å®ç°äº†åŸºäºå‘é‡çš„æ–‡æ¡£æ£€ç´¢\n",
    "7. **ç”Ÿæˆä¼˜åŒ–**: ä½¿ç”¨äº†ç¤¾åŒºéªŒè¯çš„æç¤ºè¯æ¨¡æ¿\n",
    "8. **é“¾å¼å¤„ç†**: æ„å»ºäº†å®Œæ•´çš„RAGå¤„ç†æµæ°´çº¿\n",
    "\n",
    "### ğŸš€ å…³é”®æ”¶è·\n",
    "- ç†è§£äº†RAGç³»ç»Ÿçš„å®Œæ•´å·¥ä½œæµç¨‹\n",
    "- æŒæ¡äº†LangChainçš„æ ¸å¿ƒæ¦‚å¿µå’Œç”¨æ³•\n",
    "- å­¦ä¼šäº†ä¼˜åŒ–æ–‡æœ¬å¤„ç†å’Œæ£€ç´¢ç­–ç•¥\n",
    "- äº†è§£äº†å¦‚ä½•è¯„ä¼°å’Œæ”¹è¿›RAGç³»ç»Ÿæ€§èƒ½\n",
    "\n",
    "### ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ \n",
    "åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ï¼š\n",
    "- **æŸ¥è¯¢è½¬æ¢**: å¦‚ä½•ä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢ä»¥è·å¾—æ›´å¥½çš„æ£€ç´¢ç»“æœ\n",
    "- **è·¯ç”±ç­–ç•¥**: å¦‚ä½•å¤„ç†ä¸åŒç±»å‹çš„æŸ¥è¯¢\n",
    "- **é«˜çº§ç´¢å¼•**: æ›´å¤æ‚çš„æ–‡æ¡£ç»„ç»‡å’Œç´¢å¼•ç­–ç•¥\n",
    "- **æ£€ç´¢ä¼˜åŒ–**: æå‡æ£€ç´¢è´¨é‡å’Œæ•ˆç‡çš„é«˜çº§æŠ€å·§\n",
    "\n",
    "å‡†å¤‡å¥½ç»§ç»­ä½ çš„RAGå­¦ä¹ ä¹‹æ—…äº†å—ï¼ŸğŸ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç†å’Œèµ„æºé‡Šæ”¾\n",
    "# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè®°å¾—æ¸…ç†èµ„æºä»¥é¿å…å†…å­˜æ³„æ¼\n",
    "\n",
    "# å¯é€‰ï¼šåˆ é™¤å‘é‡å­˜å‚¨ä»¥é‡Šæ”¾å†…å­˜\n",
    "# vectorstore.delete_collection()\n",
    "\n",
    "print(\"ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ\")\n",
    "print(\"ğŸ“– ç¬¬ä¸€éƒ¨åˆ†æ•™ç¨‹ç»“æŸ\")\n",
    "print(\"ğŸš€ å‡†å¤‡è¿›å…¥ç¬¬äºŒéƒ¨åˆ†ï¼šæŸ¥è¯¢è½¬æ¢\")\n",
    "\n",
    "# æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "print(f\"ğŸ’¾ å½“å‰å†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}