# test_setup.py - ç¯å¢ƒæµ‹è¯•è„šæœ¬
# ç”¨äºæµ‹è¯•RAGç³»ç»Ÿæ‰€éœ€çš„å„é¡¹ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ

# å¯¼å…¥å¿…è¦çš„åº“
from llama_index.embeddings.huggingface import HuggingFaceEmbedding  # ç”¨äºæ–‡æœ¬åµŒå…¥çš„HuggingFaceæ¨¡å‹
from llama_index.llms.google_genai import GoogleGenAI  # Google Geminiå¤§è¯­è¨€æ¨¡å‹æ¥å£
import os  # æ“ä½œç³»ç»Ÿæ¥å£
from dotenv import load_dotenv  # ç”¨äºåŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# æµ‹è¯•åµŒå…¥æ¨¡å‹
print("Testing embedding model...")
# åˆå§‹åŒ–HuggingFaceåµŒå…¥æ¨¡å‹
embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-base-en-v1.5")
# è·å–æµ‹è¯•æ–‡æœ¬çš„åµŒå…¥å‘é‡
test_embedding = embed_model.get_text_embedding("test")
print(f"âœ… Embedding model working! Vector dimension: {len(test_embedding)}")

# æµ‹è¯•LLM (å¦‚æœé…ç½®äº†APIå¯†é’¥)
if os.getenv("GOOGLE_API_KEY"):
    print("Testing Google Gemini...")
    # åˆå§‹åŒ–Google Geminiæ¨¡å‹
    llm = GoogleGenAI(model="gemini-1.5-pro")
    # å‘é€æµ‹è¯•è¯·æ±‚
    response = llm.complete("Hello, how are you?")
    print(f"âœ… Google Gemini working! Response: {response}")
else:
    print("âš ï¸  Google API key not found, skipping LLM test")

print("ğŸ‰ Environment setup complete!")